{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Valerio Pepe, CS 226r Spring 2024\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Code References:\n",
        "\n",
        "Alfredo Canziani's MNIST Tutorial: https://www.youtube.com/watch?v=OMDn66kM9Qc (base for the MNIST Model and training loop)\n",
        "\n",
        "LeNet-5 PyTorch Architecture adapted from here: https://github.com/lychengrex/LeNet-5-Implementation-Using-Pytorch/blob/master/LeNet-5%20Implementation%20Using%20Pytorch.ipynb\n",
        "\n",
        "FGSM Attack PyTorch implementation adapted from here: https://github.com/pytorch/tutorials/blob/main/beginner_source/fgsm_tutorial.py"
      ],
      "metadata": {
        "id": "c-29E49hbTnV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb9neWd1Ph-J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
        "from torch.utils.data import random_split, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z7CwN9xPp85"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.MNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "#train_data = datasets.FashionMNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "train, val = random_split(train_data, [55000,5000])\n",
        "train_loader = DataLoader(train,batch_size=32)\n",
        "val_loader = DataLoader(val, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH6JCo_ldwyZ"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "    # network structure\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        One forward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            x: input\n",
        "        '''\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.log_softmax(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        '''\n",
        "        Get the number of features in a batch of tensors `x`.\n",
        "        '''\n",
        "        size = x.size(1)*x.size(2)*x.size(3)\n",
        "       # print(size)\n",
        "        return size #np.prod(list(size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUs1Xk3TPs_S"
      },
      "outputs": [],
      "source": [
        "model = LeNet()\n",
        "model = create_feature_extractor(model, {'conv1': 'feat1',\n",
        "                                         'conv2': 'feat2',\n",
        "                                         'fc1': 'feat3',\n",
        "                                         'fc2': 'feat4',\n",
        "                                         'fc3': 'feat5',\n",
        "                                         'log_softmax': 'feat_out'})\n",
        "params = model.parameters()\n",
        "optimiser = optim.SGD(params, lr=1e-2)\n",
        "#optimiser = optim.AdamW(params)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "nb_epochs = 2\n",
        "for epoch in range(nb_epochs):\n",
        "  losses = list()\n",
        "  accuracies = list()\n",
        "  model.train()\n",
        "  for batch in train_loader:\n",
        "    x,y = batch\n",
        "\n",
        "    b = x.size(0)\n",
        "    try:\n",
        "      x = x.view(32, 1, 28, 28)\n",
        "    except RuntimeError:\n",
        "      break\n",
        "\n",
        "    l = model(x)\n",
        "    J = loss(l['feat_out'],y)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    J.backward()\n",
        "\n",
        "    optimiser.step()\n",
        "\n",
        "    losses.append(J.item())\n",
        "    accuracies.append(y.eq(l['feat_out'].detach().argmax(dim=1)).float().mean())\n",
        "\n",
        "  print(f\"Epoch {epoch + 1}\", end=\", \")\n",
        "  print(f\"Training Loss: {torch.tensor(losses).mean():.2f}\", end=\", \")\n",
        "  print(f\"Training Accuracy: {torch.tensor(accuracies).mean():.2f}\")\n",
        "\n",
        "  losses = list()\n",
        "  accuracies = list()\n",
        "  model.eval()\n",
        "  for batch in val_loader:\n",
        "    x,y = batch\n",
        "\n",
        "    b = x.size(0)\n",
        "    try:\n",
        "      x = x.view(32, 1, 28, 28)\n",
        "    except RuntimeError:\n",
        "      break\n",
        "\n",
        "    with torch.no_grad():\n",
        "      l = model(x)\n",
        "\n",
        "    J = loss(l['feat_out'],y)\n",
        "\n",
        "    losses.append(J.item())\n",
        "    accuracies.append(y.eq(l['feat_out'].detach().argmax(dim=1)).float().mean())\n",
        "\n",
        "  print(f\"Epoch {epoch + 1}\", end=\", \")\n",
        "  print(f\"Validation Loss: {torch.tensor(losses).mean():.2f}\", end=\", \")\n",
        "  print(f\"Validation Accuracy: {torch.tensor(accuracies).mean():.2f}\")\n",
        "\n",
        "  torch.save(model.state_dict(), \"CNN_MNIST-FASHION.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()\n",
        "model = create_feature_extractor(model, {'conv1': 'feat1',\n",
        "                                         'conv2': 'feat2',\n",
        "                                         'fc1': 'feat3',\n",
        "                                         'fc2': 'feat4',\n",
        "                                         'fc3': 'feat5',\n",
        "                                         'log_softmax': 'feat_out'})\n",
        "model.load_state_dict(torch.load(\"CNN_MNIST.pt\"))\n",
        "params = model.parameters()\n",
        "optimiser = optim.SGD(params, lr=1e-2)\n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "yjcZSJbmZpNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK-HNyezTu_D"
      },
      "outputs": [],
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "\n",
        "    # Clip the perturbed image values to ensure they stay within the valid range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#makes centroids\n",
        "from PIL import Image\n",
        "from numpy import asarray, divide\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from IPython.display import Image as im\n",
        "classes = range(0,10)\n",
        "centroids = {}\n",
        "#centroid_sets = [\"\",\"a\"]\n",
        "centroid_sets = [\"\"]\n",
        "\n",
        "for class_num in classes:\n",
        "  centroids[class_num] = []\n",
        "\n",
        "for centroid_set in centroid_sets:\n",
        "  for class_num in classes:\n",
        "    filestring = f\"{class_num}{centroid_set}.jpg\" #jpg for mnist, png for mnist-fashion\n",
        "    data = torch.from_numpy(divide(asarray(Image.open(filestring)),255)).float()\n",
        "    data.requires_grad = True\n",
        "    b = data.size(0)**2\n",
        "    #try:\n",
        "    data = data.view(1, 1, 28, 28)\n",
        "    #except RuntimeError:\n",
        "    #  break\n",
        "\n",
        "    features = model(data)\n",
        "\n",
        "    J = loss(features[\"feat_out\"],torch.Tensor([class_num]).type(torch.LongTensor))\n",
        "    data.retain_grad()\n",
        "    J.backward()\n",
        "    centroids[class_num].append(features)\n"
      ],
      "metadata": {
        "id": "0BQxgHXK73nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cflpLdGiUGV_"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "total = 5000\n",
        "test_num = 200\n",
        "min_eps = 0\n",
        "max_eps = 128\n",
        "\n",
        "perturb, _ = random_split(val, [test_num,total-test_num])\n",
        "perturb_loader = DataLoader(perturb, batch_size=1)\n",
        "\n",
        "graph_accuracies = dict()\n",
        "\n",
        "for eps in range(min_eps,max_eps,4):\n",
        "  losses = list()\n",
        "  accuracies = list()\n",
        "  defended_accuracies = list()\n",
        "  defended_looser = list()\n",
        "  for batch in perturb_loader:\n",
        "    x,y = batch\n",
        "    x.requires_grad = True\n",
        "    x.retain_grad()\n",
        "\n",
        "    b = x.size(0)\n",
        "    try:\n",
        "      x = x.view(1, 1, 28, 28)\n",
        "    except RuntimeError:\n",
        "      break\n",
        "\n",
        "    l = model(x)\n",
        "    J = loss(l[\"feat_out\"],y)\n",
        "    x.retain_grad()\n",
        "    J.backward()\n",
        "\n",
        "    data_grad = x.grad.data\n",
        "\n",
        "    perturbed_input = fgsm_attack(x,eps/255,data_grad)\n",
        "    b = perturbed_input.size(0)\n",
        "    try:\n",
        "      perturbed_input = perturbed_input.view(1, 1, 28, 28)\n",
        "    except RuntimeError:\n",
        "      break\n",
        "\n",
        "    perturbed_features = model(perturbed_input)\n",
        "    J_p = loss(perturbed_features[\"feat_out\"],y)\n",
        "\n",
        "    losses.append(J_p.item())\n",
        "    accuracies.append(y.eq(perturbed_features[\"feat_out\"].detach().argmax(dim=1)).float())\n",
        "\n",
        "    #DEFENSE\n",
        "\n",
        "    layer_labels = list(perturbed_features.keys())\n",
        "    similarities = {}\n",
        "    #thresholds = {0: 0.3, #MNIST Thresholds\n",
        "    #              1: 0.4,\n",
        "    #              2: 0.35,\n",
        "    #              3: 0.3,\n",
        "     #             4: 0.35,\n",
        "     #             5: 0.3,\n",
        "     #             6: 0.3,\n",
        "     #             7: 0.4,\n",
        "     #             8: 0.3,\n",
        "     #             9: 0.3}\n",
        "\n",
        "    #thresholds = {0: 0.2, #MNIST-Fashion Thresholds\n",
        "    #              1: 0.2,\n",
        "    #              2: 0.3,\n",
        "    #              3: 0.2,\n",
        "    #              4: 0.35,\n",
        "    #              5: 0.3,\n",
        "    #              6: 0.3,\n",
        "    #              7: 0.25,\n",
        "    #              8: 0.2,\n",
        "    #              9: 0.2}\n",
        "\n",
        "    for label in layer_labels:\n",
        "      similarities[label] = []\n",
        "      for index in range(len(centroid_sets)):\n",
        "        for centroid in classes:\n",
        "          sh = np.prod(list(perturbed_features[label].shape))\n",
        "          cos_sim_1 = perturbed_features[label]\n",
        "          cos_sim_2 = centroids[centroid][index][label]\n",
        "          sim = F.cosine_similarity(cos_sim_1,cos_sim_2).detach().tolist()[0]\n",
        "\n",
        "          if type(sim) == list:\n",
        "            simil_sum, simil_len = 0, 0\n",
        "            for sim_list in sim:\n",
        "              simil_sum += sum(sim_list)\n",
        "              simil_len += len(sim_list)\n",
        "            avg_sim = simil_sum/simil_len\n",
        "          else:\n",
        "            avg_sim = sim\n",
        "          similarities[label].append(avg_sim)\n",
        "        similarities[label] = [(1-i)/2 for i in similarities[label]]\n",
        "        similarities[label] = [i for i,score in enumerate(similarities[label]) if score <= thresholds[i]]\n",
        "\n",
        "    image_similarities = list(similarities.values())\n",
        "    scores = {i: 0 for i in classes}\n",
        "    scores[1000] = 0\n",
        "    for (layer,similarities) in enumerate(image_similarities):\n",
        "      score = 1\n",
        "      if len(similarities) == 0:\n",
        "        scores[1000] += round(score,1)\n",
        "      for image_class in similarities:\n",
        "        if image_class >= 10:\n",
        "          image_class -= 10\n",
        "        scores[image_class] += round(score,1)\n",
        "\n",
        "    max_scores = [list(scores.keys())[index] for index,value in enumerate(list(scores.values())) if value == max(list(scores.values()))]\n",
        "\n",
        "    defended_accuracies.append(y.eq(max_scores[0]).float())\n",
        "    defended_looser.append(float(y.item() in max_scores and len(max_scores) < 4))\n",
        "\n",
        "  graph_accuracies[eps] = [torch.tensor(accuracies).mean().item(), torch.tensor(defended_accuracies).mean().item(), torch.tensor(defended_looser).mean().item()]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eps = list(graph_accuracies.keys())\n",
        "packed_acc = list(graph_accuracies.values())\n",
        "defenseless, defended, defended_looser = list(), list(), list()\n",
        "\n",
        "for pack in packed_acc:\n",
        "  defenseless.append(pack[0])\n",
        "  defended.append(pack[1])\n",
        "  defended_looser.append(pack[2])\n",
        "\n",
        "eps = [i/255 for i in eps]\n",
        "\n",
        "plt.plot(eps, defenseless, label=\"Defenseless\")\n",
        "plt.plot(eps, defended, label=\"Defense\")\n",
        "plt.plot(eps, defended_looser, label=\"Defense (Loose)\")\n",
        "plt.plot(eps, [1/11 for i in range(len(eps))], label=\"Chance\")\n",
        "plt.title(\"LeNet accuracy against FGSM strength\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#for idx,e in enumerate(eps):\n",
        "#  print(e*255, round(e,2), defenseless[idx], defended[idx], defended_looser[idx])"
      ],
      "metadata": {
        "id": "ZP9fFP5IfilF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
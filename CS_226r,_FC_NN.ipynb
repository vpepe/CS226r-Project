{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Valerio Pepe, CS 226r Spring 2024\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Code References:\n",
        "\n",
        "Alfredo Canziani's MNIST Tutorial: https://www.youtube.com/watch?v=OMDn66kM9Qc (base for the MNIST Model and training loop)\n",
        "\n",
        "FGSM Attack PyTorch implementation adapted from here: https://github.com/pytorch/tutorials/blob/main/beginner_source/fgsm_tutorial.py"
      ],
      "metadata": {
        "id": "sQRvm2h4bDpM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Kb9neWd1Ph-J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
        "from torch.utils.data import random_split, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z7CwN9xPp85"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.MNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "#train_data = datasets.FashionMNIST(\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "train, val = random_split(train_data, [55000,5000])\n",
        "train_loader = DataLoader(train,batch_size=32)\n",
        "val_loader = DataLoader(val, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EH6JCo_ldwyZ"
      },
      "outputs": [],
      "source": [
        "class mnist_classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.linear_in = nn.Linear(28*28, 64)\n",
        "      self.linear1 = nn.Linear(64, 64)\n",
        "      self.linear2 = nn.Linear(64, 64)\n",
        "      self.linear3 = nn.Linear(64, 64)\n",
        "      self.linear4 = nn.Linear(64, 64)\n",
        "      self.linear5 = nn.Linear(64, 64)\n",
        "      self.linear_out = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = F.relu(self.linear_in(x))\n",
        "      x = F.relu(self.linear1(x))\n",
        "      x = F.relu(self.linear2(x))\n",
        "      x = F.relu(self.linear3(x))\n",
        "      x = F.relu(self.linear4(x))\n",
        "      x = F.relu(self.linear5(x))\n",
        "      x = F.log_softmax(self.linear_out(x), dim=1)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUs1Xk3TPs_S"
      },
      "outputs": [],
      "source": [
        "model = mnist_classifier()\n",
        "model = create_feature_extractor(model, {'linear_in': 'feat_in',\n",
        "                                         'linear1': 'feat1',\n",
        "                                         'linear2': 'feat2',\n",
        "                                         'linear3': 'feat3',\n",
        "                                         'linear4': 'feat4',\n",
        "                                         'linear5': 'feat5',\n",
        "                                         'log_softmax': 'feat_out'})\n",
        "params = model.parameters()\n",
        "optimiser = optim.SGD(params, lr=1e-2)\n",
        "#optimiser = optim.AdamW(params)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs):\n",
        "  losses = list()\n",
        "  accuracies = list()\n",
        "  model.train()\n",
        "  for batch in train_loader:\n",
        "    x,y = batch\n",
        "\n",
        "    b = x.size(0)\n",
        "    x = x.view(b,-1)\n",
        "\n",
        "    l = model(x)\n",
        "    J = loss(l['feat_out'],y)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    J.backward()\n",
        "\n",
        "    optimiser.step()\n",
        "\n",
        "    losses.append(J.item())\n",
        "    accuracies.append(y.eq(l['feat_out'].detach().argmax(dim=1)).float().mean())\n",
        "\n",
        "  print(f\"Epoch {epoch + 1}\", end=\", \")\n",
        "  print(f\"Training Loss: {torch.tensor(losses).mean():.2f}\", end=\", \")\n",
        "  print(f\"Training Accuracy: {torch.tensor(accuracies).mean():.2f}\")\n",
        "\n",
        "  losses = list()\n",
        "  accuracies = list()\n",
        "  model.eval()\n",
        "  for batch in val_loader:\n",
        "    x,y = batch\n",
        "\n",
        "    b = x.size(0)\n",
        "    x = x.view(b, -1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      l = model(x)\n",
        "\n",
        "    J = loss(l['feat_out'],y)\n",
        "\n",
        "    losses.append(J.item())\n",
        "    accuracies.append(y.eq(l['feat_out'].detach().argmax(dim=1)).float().mean())\n",
        "\n",
        "  print(f\"Epoch {epoch + 1}\", end=\", \")\n",
        "  print(f\"Validation Loss: {torch.tensor(losses).mean():.2f}\", end=\", \")\n",
        "  print(f\"Validation Accuracy: {torch.tensor(accuracies).mean():.2f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"FC_MNIST-FASHION.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = mnist_classifier()\n",
        "model = create_feature_extractor(model, {'linear_in': 'feat_in',\n",
        "                                         'linear1': 'feat1',\n",
        "                                         'linear2': 'feat2',\n",
        "                                         'linear3': 'feat3',\n",
        "                                         'linear4': 'feat4',\n",
        "                                         'linear5': 'feat5',\n",
        "                                         'log_softmax': 'feat_out'})\n",
        "model.load_state_dict(torch.load(\"FC_MNIST-FASHION.pt\"))\n",
        "params = model.parameters()\n",
        "optimiser = optim.SGD(params, lr=1e-2)\n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "gUjOdYaFDW5h"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mK-HNyezTu_D"
      },
      "outputs": [],
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "\n",
        "    # Clip the perturbed image values to ensure they stay within the valid range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#makes centroids\n",
        "from PIL import Image\n",
        "from numpy import asarray, divide\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from IPython.display import Image as im\n",
        "classes = range(0,10)\n",
        "centroids = {}\n",
        "#centroid_sets = [\"\",\"a\"]\n",
        "#centroid_sets = [\"\",\"a\",\"b\",\"c\",\"d\"]\n",
        "centroid_sets = [\"\"]\n",
        "\n",
        "for class_num in classes:\n",
        "  centroids[class_num] = []\n",
        "\n",
        "for centroid_set in centroid_sets:\n",
        "  for class_num in classes:\n",
        "    filestring = f\"{class_num}{centroid_set}.png\" #jpg for mnist, png for mnist-fashion\n",
        "    data = torch.from_numpy(divide(asarray(Image.open(filestring)),255)).float()\n",
        "    data.requires_grad = True\n",
        "    b = data.size(0)**2\n",
        "\n",
        "    data = data.view(1, b)\n",
        "\n",
        "    features = model(data)\n",
        "\n",
        "    J = loss(features[\"feat_out\"],torch.Tensor([class_num]).type(torch.LongTensor))\n",
        "    data.retain_grad()\n",
        "    J.backward()\n",
        "\n",
        "    centroids[class_num].append(features)"
      ],
      "metadata": {
        "id": "0BQxgHXK73nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cflpLdGiUGV_"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "import math\n",
        "\n",
        "total = 5000\n",
        "test_num = 150\n",
        "max_eps = 128\n",
        "\n",
        "perturb, _ = random_split(val, [test_num,total-test_num])\n",
        "perturb_loader = DataLoader(perturb, batch_size=1)\n",
        "\n",
        "graph_accuracies = dict()\n",
        "\n",
        "for eps in range(1,max_eps,4):\n",
        "  losses = list()\n",
        "  accuracies = list()\n",
        "  defended_accuracies = list()\n",
        "  defended_looser = list()\n",
        "  for batch in perturb_loader:\n",
        "    x,y = batch\n",
        "    x.requires_grad = True\n",
        "    x.retain_grad()\n",
        "\n",
        "    b = x.size(0)\n",
        "    x = x.view(b, -1)\n",
        "\n",
        "    l = model(x)\n",
        "    J = loss(l[\"feat_out\"],y)\n",
        "    x.retain_grad()\n",
        "    J.backward()\n",
        "\n",
        "    data_grad = x.grad.data\n",
        "\n",
        "    perturbed_input = fgsm_attack(x,eps/255,data_grad)\n",
        "    b = perturbed_input.size(0)\n",
        "    perturbed_input = perturbed_input.view(b,-1)\n",
        "\n",
        "    perturbed_features = model(perturbed_input)\n",
        "    J_p = loss(perturbed_features[\"feat_out\"],y)\n",
        "\n",
        "    losses.append(J_p.item())\n",
        "    accuracies.append(y.eq(perturbed_features[\"feat_out\"].detach().argmax(dim=1)).float())\n",
        "\n",
        "    #DEFENSE\n",
        "\n",
        "    layer_labels = list(perturbed_features.keys())\n",
        "    similarities = {}\n",
        "    #thresholds = {0: 0.3, #MNIST Thresholds\n",
        "    #              1: 0.4,\n",
        "    #              2: 0.35,\n",
        "    #              3: 0.3,\n",
        "     #             4: 0.35,\n",
        "     #             5: 0.3,\n",
        "     #             6: 0.3,\n",
        "     #             7: 0.4,\n",
        "     #             8: 0.3,\n",
        "     #             9: 0.3}\n",
        "\n",
        "    #thresholds = {0: 0.2, #MNIST-Fashion Thresholds\n",
        "    #              1: 0.2,\n",
        "    #              2: 0.3,\n",
        "    #              3: 0.2,\n",
        "    #              4: 0.35,\n",
        "    #              5: 0.3,\n",
        "    #              6: 0.3,\n",
        "    #              7: 0.25,\n",
        "    #              8: 0.2,\n",
        "    #              9: 0.2}\n",
        "    bias = 0\n",
        "\n",
        "    for label in layer_labels:\n",
        "      similarities[label] = []\n",
        "      for index in range(len(centroid_sets)):\n",
        "        for centroid in classes:\n",
        "          similarities[label].append(float(F.cosine_similarity(perturbed_features[label],centroids[centroid][index][label]).detach()))\n",
        "        similarities[label] = [(1-i)/2 for i in similarities[label]]\n",
        "        similarities[label] = [i for i,score in enumerate(similarities[label]) if score <= (thresholds[int(str(i)[-1])]+bias)]\n",
        "\n",
        "    image_similarities = list(similarities.values())\n",
        "    scores = {i: 0 for i in classes}\n",
        "    scores[1000] = 0\n",
        "    for (layer,similarities) in enumerate(image_similarities):\n",
        "      score = 1\n",
        "      if len(similarities) == 0:\n",
        "        scores[1000] += round(score,1)\n",
        "      for image_class in similarities:\n",
        "        scores[int(str(image_class)[-1])] += round(score,1)\n",
        "\n",
        "    max_scores = [list(scores.keys())[index] for index,value in enumerate(list(scores.values())) if value == max(list(scores.values()))]\n",
        "\n",
        "    defended_accuracies.append(y.eq(max_scores[0]).float())\n",
        "    defended_looser.append(float(y.item() in max_scores and len(max_scores) < 4))\n",
        "\n",
        "  graph_accuracies[eps] = [torch.tensor(accuracies).mean().item(), torch.tensor(defended_accuracies).mean().item(), torch.tensor(defended_looser).mean().item()]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eps = list(graph_accuracies.keys())\n",
        "packed_acc = list(graph_accuracies.values())\n",
        "defenseless, defended, defended_looser = list(), list(), list()\n",
        "\n",
        "for pack in packed_acc:\n",
        "  defenseless.append(pack[0])\n",
        "  defended.append(pack[1])\n",
        "  defended_looser.append(pack[2])\n",
        "\n",
        "eps = [i/255 for i in eps]\n",
        "\n",
        "plt.plot(eps, defenseless, label=\"Defenseless\")\n",
        "plt.plot(eps, defended, label=\"Defense\")\n",
        "plt.plot(eps, defended_looser, label=\"Defense (Loose)\")\n",
        "plt.plot(eps, [1/11 for i in range(len(eps))], label=\"Chance\")\n",
        "plt.title(\"Neural Network accuracy against FGSM strength\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "\n",
        "#for idx,e in enumerate(eps):\n",
        "#  print(e*255, round(e,2), defenseless[idx], defended[idx], defended_looser[idx])"
      ],
      "metadata": {
        "id": "ZP9fFP5IfilF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}